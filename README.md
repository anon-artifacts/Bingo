# ğŸ” Anonymous Repository for ASE Submission: "BINGO! Simple Optimizers Win Big if Problems Collapse to a Few Buckets"

> **Note:** This repository has been anonymized to comply with double-blind review requirements for ASE 2025. All identifying information (author names, institutional references, Git history) has been redacted. Full attribution and licensing will be restored upon acceptance.

---

## ğŸ“„ Summary

This repository contains the code, scripts, and data used to reproduce the results from our paper:

> **"BINGO! Simple Optimizers Win Big if Problems Collapse to a Few Buckets"**  
> _Submitted to ASE 2025 (Double-Blind Review)_

We present the **BINGO effect**, a prevalent data compression phenomenon in software engineering (SE) optimization. Leveraging this, we show that **simple optimizers**â€”`RANDOM`, `LITE`, `LINE`â€”perform on par with the state-of-the-art `DEHB`, while running up to **10,000Ã— faster**.

---
## ğŸ§ª Experimental Setup

All experiments were run on a 4-core Linux (Ubuntu 24.04) system (1.30GHz, 16GB RAM, no GPU).

### Configuration

- **Datasets**: 39 MOOT tasks in `data/moot/`
- **Repeats**: 20 runs per optimizer
- **Budgets**: {6, 12, 18, 24, 50, 100, 200}
- **Optimizers**: `DEHB`, `LITE`, `LINE`, `RANDOM`
- **Evaluation**:
  - Effectiveness/ Benefit: distance-to-heaven (multi-objective)
  - Cost: no. of accessed labels, wall-clock time
---
## ğŸ“Š Reproducing the Results (Table V, Figures 5 & 6)

These instructions reproduce all core results from the paper, including **Table V**, **Figure 5**, and **Figure 6**.

All experiments were run using **Python 3.13**.

---

### â¤ Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

---

### â¤ Step 2: Generate Table V

```bash
cd experiments/LUA_run_all/
make comparez
make report
```

The output will be saved to:

```
results/optimization_performance/report.csv
```

---

### â¤ Step 3: Generate Figure 5 (%Best vs. Label Budget)

```bash
cd experiments/
python3 optim_performance_comp.py
```

---

### â¤ Step 4: Generate Figure 6 (Runtime Comparison)

```bash
cd experiments/
python3 performance.py
```

---

### ğŸ§ª Optional: Re-run Optimizers

We include precomputed results for `DEHB` and `Active_Learning` (LITE) to save time. To regenerate:

```bash
# A. Remove existing results
rm -rf results/results_DEHB results/results_Active_Learning

# B. Generate commands (use NAME=Active_Learning for LITE, NAME=DEHB for DEHB)
make generate-commands NAME=Active_Learning   # or NAME=DEHB

# C. Run the optimizer
cd experiments/
./commands.sh
```

---

## ğŸ“¦ Repository Structure

```plaintext
.
â”œâ”€â”€ data/                         # Input data directory
â”‚   â””â”€â”€ moot/                     # MOOT datasets: 39 SE optimization tasks

â”œâ”€â”€ active_learning/              # Active learning source code
â”‚   â”œâ”€â”€ LICENSE.md                # Original license (MIT; redacted for double-blind)
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ bl.py                 # Contains Bayesian active learner

â”œâ”€â”€ experiments/                  # Scripts for running experiments and generating plots/tables
â”‚   â”œâ”€â”€ FileResultsReader.py      # Reads optimizer result files
â”‚   â”œâ”€â”€ LUA_run_all/              # Lua scripts containing LITE and TABLE V generation logic
â”‚   â”‚   â”œâ”€â”€ Makefile              # Automates command/script generation
â”‚   â”‚   â”œâ”€â”€ run_all.lua           # Generates TABLE V
â”‚   â”‚   â””â”€â”€ stats.lua             # Scott-Knott/effect size stats logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ experiement_runner_parallel.py  # Runs DEHB & LITE
â”‚   â”œâ”€â”€ optim_performance_comp.py       # Script to generate Fig. 5
â”‚   â””â”€â”€ performance.py           # Script to generate Fig. 6

â”œâ”€â”€ models/                       # Manages and evaluates configs
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ configurations/
â”‚   â”‚   â””â”€â”€ model_config_static.py   # Reads and manages tabular configs from MOOT
â”‚   â””â”€â”€ model_wrapper_static.py     # Wrapper class for config evaluation

â”œâ”€â”€ optimizers/                   # Optimizers implemented in the paper
â”‚   â”œâ”€â”€ ActLearnOptimizer.py      # Active learning optimizer (LITE)
â”‚   â”œâ”€â”€ DEHBOptimizer.py          # DEHB optimizer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ base_optimizer.py         # Abstract base class for all optimizers

â”œâ”€â”€ results/                      # Output directories for optimizer runs
â”‚   â”œâ”€â”€ results_Active_Learning/  # Results from LITE
â”‚   â””â”€â”€ results_DEHB/             # Results from DEHB

â””â”€â”€ utils/                        # Utility scripts and shared functions
    â”œâ”€â”€ DistanceUtil.py           # Computes "distance to heaven"
    â”œâ”€â”€ LoggingUtil.py            # Sets up and manages logging
    â”œâ”€â”€ __init__.py
    â””â”€â”€ data_loader_templated.py  # Loads and parses CSV datasets

â”œâ”€â”€ .gitignore                    # Ignore logs, cache, and other non-reproducible files
â”œâ”€â”€ LICENSE                       # MIT license (temporarily redacted)
â”œâ”€â”€ Makefile                      # Automates command/script generation and execution
â”œâ”€â”€ README.md                     # Artifact overview and reproduction instructions
â””â”€â”€ requirements.txt              # Python dependencies for experiments and plotting
```

---

## âš™ï¸ Optimizers

| Optimizer | Description |
|----------|-------------|
| `RANDOM` | Random sampling of bucketed data |
| `LITE`   | Naive Bayes-based active learner (selects high g/r) |
| `LINE`   | Diversity sampling via KMeans++ |
| `DEHB`   | Differential Evolution + Hyperband |

---

## ğŸ” License

> Temporarily redacted for double-blind review. Includes MIT-licensed components. Full license will be restored upon acceptance.

---

## ğŸ”— External Links

> Will be updated upon acceptance:
- ğŸ“œ Paper DOI
- ğŸ“ Dataset DOI
- ğŸ§ª Artifact DOI

---